{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xqLjB2cy5S7m"
   },
   "source": [
    "##Port model to TPUEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qpiJj8ym0v0-"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AoilhmYe1b5t",
    "outputId": "b88733ae-60fd-4f80-faad-8d326298d58a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import os, re, math, json, sys, shutil, pprint, datetime, scipy\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.python.platform import tf_logging\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aBDGQWkbLGvh"
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_V_VbLELLJCS"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64 #@param {type:\"integer\"}\n",
    "BUCKET = 'gs://bucket-jupyter/' #@param {type:\"string\"}\n",
    "DATA_PATH = 'data/data_4x4_13/'\n",
    "\n",
    "assert re.search(r'gs://.+', BUCKET), 'You need a GCS bucket for your Tensorboard logs. Head to http://console.cloud.google.com/storage and create one.'\n",
    "\n",
    "\n",
    "training_images_file   = BUCKET + DATA_PATH + 'train-images-idx3-ubyte'\n",
    "training_labels_file   = BUCKET + DATA_PATH + 'train-labels-idx1-ubyte'\n",
    "validation_images_file = BUCKET + DATA_PATH + 't10k-images-idx3-ubyte'\n",
    "validation_labels_file = BUCKET + DATA_PATH + 't10k-labels-idx1-ubyte'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aqKOfN9bEiCA"
   },
   "source": [
    "**IGNORE MEMORY ERRORS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0xUpYkEHEf1I"
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hm4TleyiEuLR"
   },
   "source": [
    "**TRAINING PARAMETERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XLCRba1BEw76"
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "epsilon = 1e-9    \n",
    "iter_routing = 3\n",
    "mask_with_y = True\n",
    "stddev = 0.01\n",
    "regularization_scale = 0\n",
    "gray=1          # grayscale image input\n",
    "color=3         # color image input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFGq0BQZE1Zm"
   },
   "source": [
    "#### MARGIN LOSS PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "qhdz68Xm3Z4Z"
   },
   "outputs": [],
   "source": [
    "# For Margin Loss\n",
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_val = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_trn = 8400\n",
    "batch_val = 600\n",
    "px=52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lzd6Qi464PsA"
   },
   "source": [
    "### Colab-only auth for this notebook and the TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "MPx0nvyUnvgT"
   },
   "outputs": [],
   "source": [
    "IS_COLAB_BACKEND = 'COLAB_GPU' in os.environ  # this is always set on Colab, the value is 0 or 1 depending on GPU presence\n",
    "if IS_COLAB_BACKEND:\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user() # Authenticates the backend and also the TPU using your credentials so that they can access your private GCS buckets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLZKp8bWZdmh"
   },
   "source": [
    "### TPU detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qQpdD_DSZjNY",
    "outputId": "d5dc5ac5-6a0b-4c21-8c11-6d98113723f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU or CPU\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  tpu = tf.contrib.cluster_resolver.TPUClusterResolver() # Picks up a connected TPU on Google's Colab, ML Engine, Kubernetes and Deep Learning VMs accessed through the 'ctpu up' utility\n",
    "  #tpu = tf.contrib.cluster_resolver.TPUClusterResolver('MY_TPU_NAME') # If auto-detection does not work, you can pass the name of the TPU explicitly (tip: on a VM created with \"ctpu up\" the TPU has the same name as the VM)\n",
    "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "  USE_TPU = True\n",
    "except ValueError:\n",
    "  tpu = None\n",
    "  print(\"Running on GPU or CPU\")\n",
    "  USE_TPU = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "giZwTYsJE-hB"
   },
   "source": [
    "**MODEL PARAMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2IMpncqLFCnY"
   },
   "outputs": [],
   "source": [
    "class Params(object):\n",
    "    \n",
    "    # Dataset Dimensions\n",
    "    batch_sz=4                # max value allowed by system (recommended: 64 or 128)\n",
    "    grids=4                   # 5 = 5x5 grid   \n",
    "    lip_px=13                 # pixel width of each lip image\n",
    "    pixels=grids*lip_px       # for image h & w \n",
    "    channel=gray              # image input (color or gray)\n",
    "    num_threads=4             # system limit \n",
    "    num_labels = 10           # categories\n",
    "    data_qt=9000              # total input items \n",
    "    val_qt=data_qt/15         # items used for validation\n",
    "    test_qt=data_qt/15        # items used for test\n",
    "    load_qt=data_qt-test_qt   # items loaded during training\n",
    "    train_qt=load_qt-val_qt   # items used for training (not validation)\n",
    "    height=pixels             # input image height\n",
    "    width=pixels              # input image weight\n",
    "    \n",
    "    # Saving Frequency\n",
    "    train_sum_freq=100\n",
    "    val_sum_freq=500\n",
    "    save_freq=3\n",
    "     \n",
    "    # Folder names concatenated per input dimensions\n",
    "    logdir='log_{0}x{0}_{1}'.format(grids,lip_px)\n",
    "    results='res_{0}x{0}_{1}'.format(grids,lip_px)\n",
    "    dataset='data_{0}x{0}_{1}'.format(grids,lip_px)\n",
    "    \n",
    "    # Path names\n",
    "    log_path = os.path.join('logs', logdir)        # path to dataset\n",
    "    res_path = os.path.join('results', results)    # path to dataset\n",
    "    data_path = os.path.join('data', dataset)      # path to dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kv-wP1p6XGW6"
   },
   "source": [
    "#### SHUFFLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxctLvB6XEgM"
   },
   "outputs": [],
   "source": [
    "def get_batch_data(dataset, batch_size, num_threads):\n",
    "    \n",
    "    batch_sz = Params.batch_sz  \n",
    "    \n",
    "    trX, trY, num_tr_batch, valX, valY, num_val_batch = load_data(dataset, batch_sz)\n",
    "    data_queues = tf.train.slice_input_producer([trX, trY])\n",
    "    \n",
    "    X, Y = tf.train.shuffle_batch(data_queues, num_threads=Params.num_threads, \n",
    "                                  batch_size=batch_sz, \n",
    "                                  capacity=batch_sz * 64, \n",
    "                                  min_after_dequeue=batch_sz * 32,\n",
    "                                  allow_smaller_final_batch=False)\n",
    "\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4jLzZ5fGXfSB"
   },
   "source": [
    "#### LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-p4W7706Xdt2"
   },
   "outputs": [],
   "source": [
    "def load_data(dataset, batch_sz):\n",
    "    \n",
    "    # Method Params\n",
    "    batch_sz = int(Params.batch_sz)\n",
    "    data_path = Params.data_path\n",
    "    grey = 1\n",
    "     \n",
    "    load_int=int(Params.load_qt)\n",
    "    train_int=int(Params.train_qt)\n",
    "    val_int=int(Params.val_qt)\n",
    "    \n",
    "    if (mode != tf.estimator.ModeKeys.PREDICT):\n",
    "        fd = open(os.path.join(data_path, 'train-images-idx3-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        trainX = loaded[16:].reshape((load_int, 52, 52, 1)).astype(np.float32)\n",
    "\n",
    "        fd = open(os.path.join(data_path, 'train-labels-idx1-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        trainY = loaded[8:].reshape((load_int)).astype(np.int32)\n",
    "\n",
    "        trX = trainX[:train_int] / 255.\n",
    "        trY = trainY[:train_int] \n",
    "\n",
    "        valX = trainX[train_int, ] / 255.\n",
    "        valY = trainY[train_int:]\n",
    "\n",
    "        num_tr_batch = train_int // batch_sz\n",
    "        num_val_batch = val_int // batch_sz\n",
    "\n",
    "        return trX, trY, num_tr_batch, valX, valY, num_val_batch\n",
    "    else:\n",
    "        fd = open(os.path.join(data_path, 't10k-images-idx3-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        teX = loaded[16:].reshape((Params.test_qt, Params.pixels, Params.pixels, grey)).astype(np.float)\n",
    "\n",
    "        fd = open(os.path.join(data_path, 't10k-labels-idx1-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        teY = loaded[8:].reshape((Params.test_qt)).astype(np.int32)\n",
    "\n",
    "        num_te_batch = Params.test_qt // batch_sz\n",
    "        return teX / 255., teY, num_te_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(inputs, name=None):\n",
    "    \n",
    "    batch_sz = Params.batch_sz\n",
    "    \n",
    "    name = \"shape\" if name is None else name\n",
    "    with tf.name_scope(name):\n",
    "        static_shape = inputs.get_shape().as_list()\n",
    "        dynamic_shape = tf.shape(inputs)\n",
    "        shape = []\n",
    "        for i, dim in enumerate(static_shape):\n",
    "            dim = dim if dim is not None else dynamic_shape[i]\n",
    "            shape.append(dim)\n",
    "        return(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def routing(input, b_IJ, num_outputs=10, num_dims=16):\n",
    "    \n",
    "    ''' input: Tensor shaped [batch_sz, num_caps_l=1152, 1, length(u_i)=8, 1]\n",
    "        num_caps_l: number of  layer l capsules.\n",
    "        num_outputs: number of output capsules.\n",
    "        num_dims: output capsule dimensions.\n",
    "        v_j: vector of capsule j in layer l+1\n",
    "        u_i: vector of capsule i in layer l   \n",
    "        W: [1, num_caps_i, num_caps_j * len_v_j, len_u_j, 1]\n",
    "     '''\n",
    "    batch_sz = Params.batch_sz\n",
    "    \n",
    "    input_shape = get_shape(input)\n",
    "    \n",
    "    W = tf.get_variable('Weight', shape=[1, input_shape[1], num_dims * num_outputs] + input_shape[-2:],\n",
    "                        dtype=tf.float32, initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "    \n",
    "    biases = tf.get_variable('bias', shape=(1, 1, num_outputs, num_dims, 1))\n",
    "\n",
    "    # Element-wise multiply calculates u_hat and reduce_sum\n",
    "    # reshape ops reduces time of tf.matmul operation\n",
    "    \n",
    "    # Matmul [a, b] x [b, c] = element-wise multiply [a*c, b] * [a*c, b]\n",
    "    # reduce_sum at axis=1 and reshape to [a, c]\n",
    "    \n",
    "    input = tf.tile(input, [1, 1, num_dims * num_outputs, 1, 1])\n",
    "    \n",
    "    # input.get_shape() == [batch_sz, 1152, 160, 8, 1]\n",
    "    # u_hat.get_shape() == [batch_sz, 1152, 10, 16, 1]\n",
    "    \n",
    "    u_hat = reduce_sum(W * input, axis=3, keepdims=True)\n",
    "    u_hat = tf.reshape(u_hat, shape=[-1, input_shape[1], num_outputs, num_dims, 1])\n",
    "    \n",
    "\n",
    "    # u_hat_stopped = u_hat in forward propagation.  \n",
    "    # Gradient not passed back u_hat_stopped to u_hat in backpropagation\n",
    "    \n",
    "    u_hat_stopped = tf.stop_gradient(u_hat, name='stop_gradient')\n",
    "\n",
    "    for r_iter in range(iter_routing):\n",
    "        with tf.variable_scope('iter_' + str(r_iter)):\n",
    "\n",
    "            # => [batch_sz, 1152, 10, 1, 1]\n",
    "            c_IJ = softmax(b_IJ, axis=2)\n",
    "\n",
    "            # Final iter uses u_hat to receive gradients from graph\n",
    "            if r_iter == iter_routing - 1:\n",
    "\n",
    "                # weight u_hat with c_IJ, element-wise dimension => [batch_sz, 1152, 10, 16, 1]\n",
    "                s_J = tf.multiply(c_IJ, u_hat)\n",
    "                \n",
    "                # sum second dimension = [batch_sz, 1, 10, 16, 1]\n",
    "                # s_J.get_shape() == [batch_sz, 1, num_outputs, num_dims, 1]\n",
    "                s_J = reduce_sum(s_J, axis=1, keepdims=True) + biases\n",
    "\n",
    "                # squash v_J.get_shape() == [batch_sz, 1, 10, 16, 1]\n",
    "                v_J = squash(s_J)\n",
    "                \n",
    "            # No backpropagation here\n",
    "            elif r_iter < iter_routing - 1:  \n",
    "                s_J = tf.multiply(c_IJ, u_hat_stopped)\n",
    "                s_J = reduce_sum(s_J, axis=1, keepdims=True) + biases\n",
    "                v_J = squash(s_J)\n",
    "\n",
    "                # reshape & tile v_j [batch_sz ,1, 10, 16, 1] to [batch_sz, 1152, 10, 16, 1]\n",
    "                # matmul in the last two dim: [16, 1].T x [16, 1] => [1, 1], reduce mean in the\n",
    "                # batch_sz dim, resulting in [1, 1152, 10, 1, 1]\n",
    "                v_J_tiled = tf.tile(v_J, [1, input_shape[1], 1, 1, 1])\n",
    "                u_produce_v = reduce_sum(u_hat_stopped * v_J_tiled, axis=3, keepdims=True)\n",
    "                \n",
    "                # u_produce_v.get_shape() == [batch_sz, 1152, 10, 1, 1]\n",
    "                # b_IJ += tf.reduce_sum(u_produce_v, axis=0, keep_dims=True)\n",
    "                b_IJ += u_produce_v\n",
    "\n",
    "    return(v_J)    # Returns: Tensor shaped [batch_sz, num_caps_l_plus_1, length(v_j)=16, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lz1Zknfk4qCx"
   },
   "source": [
    "### CapsLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZE8dgyPC1_6m"
   },
   "outputs": [],
   "source": [
    "class CapsLayer(object):\n",
    "    ''' Capsule layer.\n",
    "    Args:\n",
    "        input: A 4-D tensor.\n",
    "        num_outputs: number capsules in layer\n",
    "        vec_len: integer, the length of the output vector of a capsule.\n",
    "        layer_type: string, one of 'FC' or \"CONV\", the type of this layer,\n",
    "            fully connected or convolution, for the future expansion capability\n",
    "        with_routing: boolean, this capsule is routing with the lower-level layer capsule.\n",
    "\n",
    "    Returns:\n",
    "        A 4-D tensor.\n",
    "    '''\n",
    "    \n",
    "    batch_sz = Params.batch_sz\n",
    "    \n",
    "    def __init__(self, num_outputs, vec_len, with_routing=True, layer_type='FC'):\n",
    "        self.num_outputs = num_outputs\n",
    "        self.vec_len = vec_len\n",
    "        self.with_routing = with_routing\n",
    "        self.layer_type = layer_type\n",
    "\n",
    "    def __call__(self, input, kernel_size=None, stride=None):\n",
    "        \n",
    "        # Parameters 'kernel_size' and 'stride' will be used while layer_type = CONV\n",
    "                \n",
    "        batch_sz = Params.batch_sz\n",
    "        \n",
    "        if self.layer_type == 'CONV':\n",
    "            self.kernel_size = kernel_size\n",
    "            self.stride = stride\n",
    "            if not self.with_routing:\n",
    "                # the PrimaryCaps layer, a convolutional layer\n",
    "                # input: [batch_sz, 20, 20, 256]\n",
    "                # assert input.get_shape() == [batch_sz, 20, 20, 256]\n",
    "\n",
    "                # NOTE: I can't find out any words from the paper whether the\n",
    "                # PrimaryCap convolution does a ReLU activation or not before\n",
    "                # squashing function, but experiment show that using ReLU get a\n",
    "                # higher test accuracy. So, which one to use will be your choice\n",
    "                capsules = tf.contrib.layers.conv2d(input, self.num_outputs * self.vec_len,\n",
    "                                                    self.kernel_size, self.stride, padding=\"VALID\",\n",
    "                                                    activation_fn=tf.nn.relu)\n",
    "                # capsules = tf.contrib.layers.conv2d(input, self.num_outputs * self.vec_len,\n",
    "                #                                    self.kernel_size, self.stride,padding=\"VALID\",\n",
    "                #                                    activation_fn=None)\n",
    "                capsules = tf.reshape(capsules, (batch_sz, -1, self.vec_len, 1))\n",
    "\n",
    "                # return tensor with shape [batch_sz, 1152, 8, 1]\n",
    "                capsules = squash(capsules)\n",
    "                return(capsules)\n",
    "\n",
    "        if self.layer_type == 'FC':\n",
    "            if self.with_routing:\n",
    "                # the DigitCaps layer is fully connected (FC) layer\n",
    "                # Reshapes to [batch_sz, 1152, 1, 8, 1]\n",
    "                self.input = tf.reshape(input, shape=(batch_sz, -1, 1, input.shape[-2].value, 1))\n",
    "\n",
    "                with tf.variable_scope('routing'):\n",
    "                    # b_IJ: [batch_sz, num_caps_l, num_caps_l_plus_1, 1, 1],\n",
    "                    # about the reason of using 'batch_sz', see issue #21\n",
    "                    b_IJ = tf.constant(np.zeros([batch_sz, input.shape[1].value, self.num_outputs, 1, 1], dtype=np.float32))\n",
    "                    capsules = routing(self.input, b_IJ, num_outputs=self.num_outputs, num_dims=self.vec_len)\n",
    "                    capsules = tf.squeeze(capsules, axis=1)\n",
    "\n",
    "            return(capsules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(vector):\n",
    "      \n",
    "    '''\n",
    "    vector: Tensor shaped [batch_sz, 1, num_caps, vec_len, 1] or [batch_sz, num_caps, vec_len, 1].\n",
    "    \n",
    "    Returns squashed tensor with 'vec_len' dimensions in same shape as vector.\n",
    "    '''\n",
    "    vec_squared_norm = reduce_sum(tf.square(vector), -2, keepdims=True)\n",
    "    scalar_factor = vec_squared_norm / (1 + vec_squared_norm) / tf.sqrt(vec_squared_norm + epsilon)\n",
    "    vec_squashed = scalar_factor * vector  # element-wise\n",
    "    \n",
    "    return(vec_squashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(imgs, size, save_path):\n",
    "    \n",
    "    batch_sz = Params.batch_sz\n",
    "    \n",
    "    '''\n",
    "    Args:\n",
    "        imgs: shaped [batch_sz, image_height, image_width]\n",
    "        size: two integers  [image_height, image_width]\n",
    "        save_path: path to save data\n",
    "    '''\n",
    "    \n",
    "    imgs = (imgs + 1.) / 2    \n",
    "    \n",
    "    return(scipy.misc.imsave(save_path, mergeImgs(imgs, size)))\n",
    "\n",
    "def mergeImgs(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    imgs = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        imgs[j * h:j * h + h, i * w:i * w + w, :] = image\n",
    "\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_sum(input_tensor, axis=None, keepdims=False):\n",
    "    \n",
    "    batch_sz = Params.batch_sz\n",
    "    \n",
    "    try:\n",
    "        return tf.reduce_sum(input_tensor, axis=axis, keepdims=keepdims)\n",
    "    except:\n",
    "        return tf.reduce_sum(input_tensor, axis=axis, keep_dims=keepdims)    # alt for version compatibility\n",
    "    \n",
    "def softmax(logits, axis=None):\n",
    "    try:\n",
    "        return tf.nn.softmax(logits, axis=axis)\n",
    "    except:\n",
    "        return tf.nn.softmax(logits, dim=axis)    # alt for version compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZwsJf1DzFK2b"
   },
   "source": [
    "## LipCapsule Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "id": "dbYGt7qDF2OL",
    "outputId": "de72489a-851b-4294-b5ed-53b9e4efd485"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Params' has no attribute 'num_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-d704581676a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mLipCapsule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mnum_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-144-d704581676a7>\u001b[0m in \u001b[0;36mLipCapsule\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mnum_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mchannel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mParams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'Params' has no attribute 'num_label'"
     ]
    }
   ],
   "source": [
    "class LipCapsule(object):\n",
    "    \n",
    "    height = Params.height\n",
    "    width = Params.width\n",
    "    num_label = Params.num_label\n",
    "    channel=Params.channel\n",
    "\n",
    "    def __init__(self, training=(mode == tf.estimator.ModeKeys.TRAIN), height=height, width=width, channels=channel, num_label=num_label):\n",
    "\n",
    "        self.batch_sz = Params.batch_sz\n",
    "        self.dataset = Params.dataset\n",
    "        self.num_threads = Params.num_threads\n",
    "        self.graph = tf.Graph()\n",
    "        self.mode = tf.estimator.ModeKeys.TRAIN \n",
    "        self.step = tf.train.get_or_create_global_step()\n",
    "        # features, labels, mode, params\n",
    "        self.X, self.labels = get_batch_data(self.dataset, self.batch_sz, self.num_threads)\n",
    "        self.dataset=Params.dataset\n",
    "        # loss = tf.losses.softmax_cross_entropy(labels, logits)\n",
    "        # Step increased per GLOBAL_BATCH_SIZE = 8 * BATCH_SIZE\n",
    "        # Must adjust learning rate schedule accordingly\n",
    "        lr = 0.0001 + tf.train.exponential_decay(0.01, step, 600//8, 1/math.e)\n",
    "        # Wrap optimizer in a CrossShardOptimizer for multi-core training\n",
    "        optimizer = tf.contrib.tpu.CrossShardOptimizer(tf.train.AdamOptimizer(lr))  \n",
    "        \n",
    "        # Running averages need updating after each batch.\n",
    "        # train_op = tf.contrib.training.create_train_op(loss, optimizer)\n",
    "\n",
    "        self.Y = tf.one_hot(self.labels, depth=self.num_label, axis=1, dtype=tf.float32)\n",
    "\n",
    "        \n",
    "        logits = tf.layers.Dense(10)(y)\n",
    "        predictions = tf.nn.softmax(logits)\n",
    "        classes = tf.math.argmax(predictions, axis=-1)\n",
    "\n",
    "        if (mode == tf.estimator.ModeKeys.PREDICT):    \n",
    "            self.X = tf.placeholder(tf.float32, shape=(batch_sz, self.height, \n",
    "                                                       self.width, \n",
    "                                                       self.channels))\n",
    "            self.labels = tf.placeholder(tf.int32, shape=(batch_sz, ))\n",
    "            self.Y = tf.reshape(self.labels, shape=(batch_sz, self.num_label, 1))\n",
    "            self.build_arch()\n",
    "            \n",
    "        else:\n",
    "            self.X, self.labels = get_batch_data(self.dataset, batch_sz, \n",
    "                                                 self.num_threads)\n",
    "            self.Y = tf.one_hot(self.labels, depth=self.num_label, axis=1, \n",
    "                                dtype=tf.float32)\n",
    "\n",
    "            self.build_arch()\n",
    "            self.loss()\n",
    "            self._summary()\n",
    "\n",
    "            # t_vars = tf.trainable_variables()\n",
    "            self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "            self.train_op = self.optimizer.minimize(self.total_loss, global_step=self.global_step)\n",
    "\n",
    "\n",
    "\n",
    "    tf.logging.info('Setting up the main structure')\n",
    "\n",
    "    def build_arch(self):\n",
    "        \n",
    "        batch_sz = Params.batch_sz\n",
    "        \n",
    "        with tf.variable_scope('Conv1_layer'):\n",
    "            # Conv1, return tensor with shape [batch_sz, 20, 20, 256]\n",
    "            conv1 = tf.contrib.layers.conv2d(self.X, num_outputs=256,\n",
    "                                             kernel_size=9, stride=1,\n",
    "                                             padding='VALID')\n",
    "\n",
    "        # Primary Capsules layer returns tensor shaped [batch_sz, 1152, 8, 1]\n",
    "        with tf.variable_scope('PrimaryCaps_layer'):\n",
    "            primaryCaps = CapsLayer(num_outputs=32, vec_len=8, \n",
    "                                    with_routing=False, layer_type='CONV')\n",
    "            caps1 = primaryCaps(conv1, kernel_size=9, stride=2)\n",
    "\n",
    "        # DigitCaps layer, return shape [batch_sz, 10, 16, 1]\n",
    "        with tf.variable_scope('DigitCaps_layer'):\n",
    "            digitCaps = CapsLayer(num_outputs=self.num_label, vec_len=16, \n",
    "                                  with_routing=True, layer_type='FC')\n",
    "            self.caps2 = digitCaps(caps1)\n",
    "\n",
    "        with tf.variable_scope('Masking'):\n",
    "            # calc ||v_c|| and softmax(||v_c||)\n",
    "            # [batch_sz, 10, 16, 1] => [batch_sz, 10, 1, 1]\n",
    "            self.v_length = tf.sqrt(reduce_sum(tf.square(self.caps2),\n",
    "                                               axis=2, keepdims=True) + epsilon)\n",
    "            self.softmax_v = softmax(self.v_length, axis=1)\n",
    "            # self.softmax_v.get_shape() == [batch_sz, self.num_label, 1, 1]\n",
    "\n",
    "            # picks out index of max softmax val of 10 caps\n",
    "            # [batch_sz, 10, 1, 1] => [batch_sz] (index)\n",
    "            self.argmax_idx = tf.to_int32(tf.argmax(self.softmax_v, axis=1))\n",
    "            # self.argmax_idx.get_shape() == [batch_sz, 1, 1]\n",
    "            self.argmax_idx = tf.reshape(self.argmax_idx, shape=(batch_sz, ))\n",
    "\n",
    "            # Not Masking\n",
    "            if not mask_with_y:\n",
    "                # 4-dimensional indexing process\n",
    "                masked_v = []\n",
    "                for batch_sz in range(batch_sz):\n",
    "                    v = self.caps2[batch_sz][self.argmax_idx[batch_sz], :]\n",
    "                    masked_v.append(tf.reshape(v, shape=(1, 1, 16, 1)))\n",
    "\n",
    "                self.masked_v = tf.concat(masked_v, axis=0)\n",
    "                assert self.masked_v.get_shape() == [batch_sz, 1, 16, 1]\n",
    "                \n",
    "            # Masking\n",
    "            else:\n",
    "                self.masked_v = tf.multiply(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, self.num_label, 1)))\n",
    "                self.v_length = tf.sqrt(reduce_sum(tf.square(self.caps2), axis=2, \n",
    "                                                   keepdims=True) + epsilon)\n",
    "\n",
    "        # MIRACL-VC1 images reconstructed with three (FC) layers\n",
    "        # [batch_sz, 1, 16, 1] => [batch_sz, 16] => [batch_sz, 512]\n",
    "        with tf.variable_scope('Decoder'):\n",
    "            vector_j = tf.reshape(self.masked_v, shape=(batch_sz, -1))\n",
    "            fc1 = tf.contrib.layers.fully_connected(vector_j, num_outputs=512)\n",
    "            fc2 = tf.contrib.layers.fully_connected(fc1, num_outputs=1024)\n",
    "            self.decoded = tf.contrib.layers.fully_connected(\n",
    "                fc2, num_outputs=self.height * self.width * self.channels, \n",
    "                activation_fn=tf.sigmoid)\n",
    "\n",
    "    def loss(self):\n",
    "        \n",
    "        # batch_sz = Params.batch_sz\n",
    "        #  Margin loss [batch_sz, 10, 1, 1]\n",
    "        # max_l = max(0, m_plus-||v_c||)^2\n",
    "        max_l = tf.square(tf.maximum(0., m_plus - self.v_length))\n",
    "        # max_r = max(0, ||v_c||-m_minus)^2\n",
    "        max_r = tf.square(tf.maximum(0., self.v_length - m_minus))\n",
    "        assert max_l.get_shape() == [batch_sz, self.num_label, 1, 1]\n",
    "\n",
    "        # Reshapes [batch_sz, 10, 1, 1] => [batch_sz, 10]\n",
    "        max_l = tf.reshape(max_l, shape=(batch_sz, -1))\n",
    "        max_r = tf.reshape(max_r, shape=(batch_sz, -1))\n",
    "\n",
    "        # calc T_c: [batch_sz, 10]\n",
    "        T_c = self.Y    # T_c = Y\n",
    "        # element-wise multiply [batch_sz, 10]\n",
    "        L_c = T_c * max_l + lambda_val * (1 - T_c) * max_r\n",
    "\n",
    "        self.margin_loss = tf.reduce_mean(tf.reduce_sum(L_c, axis=1))\n",
    "\n",
    "        # Reconstruction loss\n",
    "        orgin = tf.reshape(self.X, shape=(batch_sz, -1))\n",
    "        squared = tf.square(self.decoded - orgin)\n",
    "        self.reconstruction_err = tf.reduce_mean(squared)\n",
    "\n",
    "        # Mean squared error calculated with reduce_mean (reconstruction loss)\n",
    "        self.total_loss = self.margin_loss + regularization_scale * self.reconstruction_err\n",
    "\n",
    "    # Summary\n",
    "    def _summary(self):\n",
    "        \n",
    "        batch_sz = Params.batch_sz\n",
    "        \n",
    "        train_summary = []\n",
    "        train_summary.append(tf.summary.scalar('train/margin_loss', self.margin_loss))\n",
    "        train_summary.append(tf.summary.scalar('train/reconstruction_loss', self.reconstruction_err))\n",
    "        train_summary.append(tf.summary.scalar('train/total_loss', self.total_loss))\n",
    "        recon_img = tf.reshape(self.decoded, shape=(batch_sz, self.height, self.width, self.channels))\n",
    "        train_summary.append(tf.summary.image('reconstruction_img', recon_img))\n",
    "        self.train_summary = tf.summary.merge(train_summary)\n",
    "\n",
    "        correct_prediction = tf.equal(tf.to_int32(self.labels), self.argmax_idx)\n",
    "        self.accuracy = tf.reduce_sum(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "model_fn=LipCapsule()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KIc0oqiD40HC"
   },
   "source": [
    "### Estimator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeIxkrv9Wihg"
   },
   "outputs": [],
   "source": [
    "# Transforms data to be sent to model input_fn. \n",
    "# Produces a Tensorflow graph to be prepended to model graph. \n",
    "\n",
    "def serving_input_fn():\n",
    "    # placeholder for the data received by the API (already parsed, no JSON decoding necessary,\n",
    "    # but the JSON must contain one or multiple 'image' key(s) with px x px greyscale images  as content.)\n",
    "    \n",
    "    inputs = {\"serving_input\": tf.placeholder(tf.float32, [None, px, px])}  \n",
    "    # should match shape of JSON\n",
    "    features = inputs['serving_input']  # no transformation needed\n",
    "    \n",
    "    return tf.estimator.export.TensorServingInputReceiver(features, inputs) # needed by model_fn\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "56y8UNFQIVwj"
   },
   "outputs": [],
   "source": [
    "# TPU REFACTORING: model_fn must have a params argument. \n",
    "# TPUEstimator passes batch_size and use_tpu into it\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "  \n",
    "  training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  x = features\n",
    "  y = tf.reshape(x, [-1, px, px, 1])\n",
    "\n",
    "  y = tf.layers.Conv2D(filters=6, kernel_size=3, padding='same', use_bias=False)(y) # no bias necessary before batch norm\n",
    "  y = tf.layers.BatchNormalization(scale=False, center=True)(y, training=mode) # no batch norm scaling necessary before \"relu\"\n",
    "  y = tf.nn.relu(y) # activation after batch norm\n",
    "\n",
    "  y = tf.layers.Conv2D(filters=12, kernel_size=6, padding='same', use_bias=False, strides=2)(y)\n",
    "  y = tf.layers.BatchNormalization(scale=False, center=True)(y, training=mode)\n",
    "  y = tf.nn.relu(y)\n",
    "\n",
    "  y = tf.layers.Conv2D(filters=24, kernel_size=6, padding='same', use_bias=False, strides=2)(y)\n",
    "  y = tf.layers.BatchNormalization(scale=False, center=True)(y, training=mode)\n",
    "  y = tf.nn.relu(y)\n",
    "\n",
    "  y = tf.layers.Flatten()(y)\n",
    "  y = tf.nn.relu(y)\n",
    "  \n",
    "  logits = tf.layers.Dense(10)(y)\n",
    "  predictions = tf.nn.softmax(logits)\n",
    "  classes = tf.math.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to():\n",
    "    res_path = os.path.join('results', results)\n",
    "    batch_sz = Params.batch_sz        \n",
    "    loss = res_path + '/loss.csv'\n",
    "    train_acc = res_path + '/train_acc.csv'\n",
    "    val_acc = res_path + '/val_acc.csv'\n",
    "    fd_train_acc = open(train_acc, 'w')\n",
    "    fd_train_acc.write('step,train_acc\\n')\n",
    "    fd_loss = open(loss, 'w')\n",
    "    fd_loss.write('step,loss\\n')\n",
    "    fd_val_acc = open(val_acc, 'w')\n",
    "    fd_val_acc.write('step,val_acc\\n')\n",
    "    return(fd_train_acc, fd_loss, fd_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6r6qZpcye6__"
   },
   "outputs": [],
   "source": [
    "def train(model, estimator, num_labels):\n",
    "    \n",
    "    batch_sz=int(Params.batch_sz)\n",
    "    val_sum_freq=int(Params.val_sum_freq)\n",
    "    dataset=str(Params.dataset)\n",
    "    \n",
    "    trX, trY, num_tr_batch, valX, valY, num_val_batch = load_data(dataset, batch_sz)\n",
    "    Y = valY[:num_val_batch * batch_sz].reshape((-1, 1))\n",
    "\n",
    "    fd_train_acc, fd_loss, fd_val_acc = save_to()\n",
    "    \n",
    "    with supervisor.managed_session() as sess:\n",
    "        for epoch in range(epochs):\n",
    "            print(\"\\n Training.  Epoch %d/%d:\" % (epoch, epochs))\n",
    "            if supervisor.should_stop():\n",
    "                print('\\n Supervisor stoped! \\n ')\n",
    "                break\n",
    "            for step in tqdm(range(num_tr_batch), total=num_tr_batch, ncols=50, leave=False, unit='b'):\n",
    "                start = step * batch_sz\n",
    "                end = start + batch_sz\n",
    "                global_step = epoch * num_tr_batch + step\n",
    "\n",
    "                if global_step % Params.train_sum_freq == 0:\n",
    "                    _, loss, train_acc, summary_str = sess.run([model.train_op, model.total_loss, \n",
    "                                                                model.accuracy, model.train_summary])\n",
    "                    assert not np.isnan(loss), 'LOSS NAN ERROR'\n",
    "                    \n",
    "                    supervisor.summary_writer.add_summary(summary_str, global_step)\n",
    "\n",
    "                    fd_loss.write(str(global_step) + ',' + str(loss) + \"\\n\")\n",
    "                    fd_loss.flush()\n",
    "                    fd_train_acc.write(str(global_step) + ',' + str(train_acc / batch_sz) + \"\\n\")\n",
    "                    fd_train_acc.flush()\n",
    "                else:\n",
    "                    sess.run(model.train_op)\n",
    "\n",
    "                if val_sum_freq != 0 and (global_step) % val_sum_freq == 0:\n",
    "                    val_acc = 0\n",
    "                    for i in range(num_val_batch):\n",
    "                        start = i * batch_sz\n",
    "                        end = start + batch_sz\n",
    "                        acc = sess.run(model.accuracy, {model.X: valX[start:end], model.labels: valY[start:end]})\n",
    "                        val_acc += acc\n",
    "                    val_acc = val_acc / (batch_sz * num_val_batch)\n",
    "                    fd_val_acc.write(str(global_step) + ',' + str(val_acc) + '\\n')\n",
    "                    fd_val_acc.flush()\n",
    "\n",
    "            if (epoch + 1) % save_freq == 0:\n",
    "                supervisor.saver.save(sess, log_path + '/model_epoch_%04d_step_%02d' % (epoch, global_step))\n",
    "\n",
    "        fd_val_acc.close()\n",
    "        fd_train_acc.close()\n",
    "        fd_loss.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RxpRgF874-ix"
   },
   "source": [
    "### Train and validate the model on TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label(tf_bytestring):\n",
    "    label = tf.decode_raw(tf_bytestring, tf.uint8)\n",
    "    label = tf.reshape(label, [])\n",
    "    return label\n",
    "  \n",
    "def read_image(tf_bytestring):\n",
    "    image = tf.decode_raw(tf_bytestring, tf.uint8)\n",
    "    image = tf.cast(image, tf.float32)/256.0\n",
    "    image = tf.reshape(image, [px*px])\n",
    "    return image\n",
    "  \n",
    "def load_dataset(image_file, label_file):\n",
    "    imagedataset = tf.data.FixedLengthRecordDataset(image_file, px*px, header_bytes=16)\n",
    "    imagedataset = imagedataset.map(read_image, num_parallel_calls=16)\n",
    "    labelsdataset = tf.data.FixedLengthRecordDataset(label_file, 1, header_bytes=8)\n",
    "    labelsdataset = labelsdataset.map(read_label, num_parallel_calls=16)\n",
    "    dataset = tf.data.Dataset.zip((imagedataset, labelsdataset))\n",
    "    return dataset \n",
    "  \n",
    "def get_training_dataset(image_file, label_file, batch_size):\n",
    "    dataset = load_dataset(image_file, label_file)\n",
    "    dataset = dataset.cache()  # Cached in RAM\n",
    "    dataset = dataset.shuffle(batch_val, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.repeat() # Mandatory for TPU  \n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True) # Important on TPU\n",
    "    dataset = dataset.prefetch(-1)  # Prefetches next batch while training  (-1: prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "# def get_validation_dataset(image_file, label_file):\n",
    "def get_validation_dataset(image_file, label_file, batch_size):\n",
    "    dataset = load_dataset(image_file, label_file)\n",
    "    dataset = dataset.cache() # cached in RAM\n",
    "\n",
    "    # dataset = dataset.batch(batch_test, drop_remainder=True) \n",
    "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.repeat() # Mandatory for TPU for now\n",
    "    return dataset\n",
    "\n",
    "# instantiate the datasets\n",
    "training_dataset = get_training_dataset(training_images_file, training_labels_file, BATCH_SIZE)\n",
    "validation_dataset = get_validation_dataset(validation_images_file, validation_labels_file, batch_val)\n",
    "\n",
    "# For TPU, we will need a function that returns the dataset\n",
    "\n",
    "# TPU REFACTORING: input_fn's must have a params argument though which TPUEstimator passes params['batch_size']\n",
    "# training_input_fn = lambda: get_training_dataset(training_images_file, training_labels_file, BATCH_SIZE)\n",
    "# validation_input_fn = lambda: get_validation_dataset(validation_images_file, validation_labels_file)\n",
    "training_input_fn = lambda params: get_training_dataset(training_images_file, training_labels_file, params['batch_size'])\n",
    "validation_input_fn = lambda params: get_validation_dataset(validation_images_file, validation_labels_file, params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TTwH_P-ZJ_xx",
    "outputId": "462727ee-c1b2-43ad-8806-6e543d69e35e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x000002594824FF28>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'gs://bucket-jupyter/lipjobs_1/job-2019-08-10-00:52:34', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025947F9D2B0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=16, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running train on CPU\n",
      "INFO:tensorflow:Error recorded from training_loop: `pred` must be a Tensor, or a Python bool, or 1 or 0. Found instead: train\n",
      "INFO:tensorflow:training_loop marked as finished\n",
      "WARNING:tensorflow:Reraising captured error\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "`pred` must be a Tensor, or a Python bool, or 1 or 0. Found instead: train",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-26a81fdda458>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     config=training_config, use_tpu=USE_TPU, export_to_tpu=False) # supported on ML Engine\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_input_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_input_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\contrib\\tpu\\python\\tpu\\tpu_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m   2455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training_loop'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2457\u001b[1;33m       \u001b[0mrendezvous\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2459\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\contrib\\tpu\\python\\tpu\\error_handling.py\u001b[0m in \u001b[0;36mraise_errors\u001b[1;34m(self, timeout_sec)\u001b[0m\n\u001b[0;32m    126\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Reraising captured error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkept_errors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\contrib\\tpu\\python\\tpu\\tpu_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m   2450\u001b[0m           \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2451\u001b[0m           \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2452\u001b[1;33m           saving_listeners=saving_listeners)\n\u001b[0m\u001b[0;32m   2453\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2454\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'training_loop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1152\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m-> 1154\u001b[1;33m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[0;32m   1155\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\contrib\\tpu\\python\\tpu\\tpu_estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   2249\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2250\u001b[0m       return super(TPUEstimator, self)._call_model_fn(features, labels, mode,\n\u001b[1;32m-> 2251\u001b[1;33m                                                       config)\n\u001b[0m\u001b[0;32m   2252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2253\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_model_fn_for_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1113\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\contrib\\tpu\\python\\tpu\\tpu_estimator.py\u001b[0m in \u001b[0;36m_model_fn\u001b[1;34m(features, labels, mode, config, params)\u001b[0m\n\u001b[0;32m   2532\u001b[0m           \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Running %s on CPU'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2533\u001b[0m           estimator_spec = model_fn_wrapper.call_without_tpu(\n\u001b[1;32m-> 2534\u001b[1;33m               features, labels, is_export_mode=is_export_mode)\n\u001b[0m\u001b[0;32m   2535\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_every_n_steps\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2536\u001b[0m             estimator_spec = estimator_spec._replace(\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\contrib\\tpu\\python\\tpu\\tpu_estimator.py\u001b[0m in \u001b[0;36mcall_without_tpu\u001b[1;34m(self, features, labels, is_export_mode)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_without_tpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_export_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_export_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_export_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mconvert_to_single_tpu_train_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdequeue_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\contrib\\tpu\\python\\tpu\\tpu_estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, is_export_mode)\u001b[0m\n\u001b[0;32m   1591\u001b[0m       \u001b[0m_add_item_to_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_CTX_KEY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1593\u001b[1;33m     \u001b[0mestimator_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1594\u001b[0m     if (running_on_cpu and\n\u001b[0;32m   1595\u001b[0m         isinstance(estimator_spec, model_fn_lib._TPUEstimatorSpec)):  # pylint: disable=protected-access\n",
      "\u001b[1;32m<ipython-input-156-04d4e27b10d5>\u001b[0m in \u001b[0;36mmodel_fn\u001b[1;34m(features, labels, mode, params)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# no bias necessary before batch norm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m   \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# no batch norm scaling necessary before \"relu\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m   \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# activation after batch norm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m       \u001b[1;31m# Actually call layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;31m# In graph mode, failure to build the layer's graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;31m# implies a user-side bug. We don't catch exceptions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\python\\layers\\normalization.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[1;31m# Currently never reaches here since fused_batch_norm does not support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     output, mean, variance = tf_utils.smart_cond(\n\u001b[1;32m--> 457\u001b[1;33m         training, _fused_batch_norm_training, _fused_batch_norm_inference)\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bessels_correction_test_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[1;31m# Remove Bessel's correction to be consistent with non-fused batch norm.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0;32m     53\u001b[0m   return smart_module.smart_cond(\n\u001b[1;32m---> 54\u001b[1;33m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`false_fn` must be callable.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m   \u001b[0mpred_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmart_constant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py\u001b[0m in \u001b[0;36msmart_constant_value\u001b[1;34m(pred)\u001b[0m\n\u001b[0;32m     87\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     raise TypeError(\"`pred` must be a Tensor, or a Python bool, or 1 or 0. \"\n\u001b[1;32m---> 89\u001b[1;33m                     \"Found instead: %s\" % pred)\n\u001b[0m\u001b[0;32m     90\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: `pred` must be a Tensor, or a Python bool, or 1 or 0. Found instead: train"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "# uses all 8 cores\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE * 8\n",
    "\n",
    "# TPUEstimator increments step once per GLOBAL_BATCH_SIZE\n",
    "steps_per_epoch = batch_trn // GLOBAL_BATCH_SIZE  # batch_trn images in training dataset\n",
    "\n",
    "MODEL_EXPORT_NAME = \"model_export\"  # name for exporting saved model\n",
    "\n",
    "# Mltiple training steps before reporting\n",
    "TPU_ITERATIONS_PER_LOOP = steps_per_epoch # report back after each epoch\n",
    "\n",
    "tf_logging.set_verbosity(tf_logging.INFO)\n",
    "now = datetime.datetime.now()\n",
    "MODEL_DIR = BUCKET+\"lipjobs_1/job\" + \"-{}-{:02d}-{:02d}-{:02d}:{:02d}:{:02d}\".format(now.year, now.month, now.day, now.hour, now.minute, now.second)\n",
    "\n",
    "# RunConfig changed\n",
    "training_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster=tpu, model_dir=MODEL_DIR,\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(TPU_ITERATIONS_PER_LOOP))\n",
    "   \n",
    "# call export_savedmodel after training\n",
    "    \n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    model_fn=model_fn, model_dir=MODEL_DIR,\n",
    "    train_batch_size=GLOBAL_BATCH_SIZE,\n",
    "    eval_batch_size=batch_val,  \n",
    "\n",
    "    config=training_config, use_tpu=USE_TPU, export_to_tpu=False) # supported on ML Engine\n",
    "\n",
    "estimator.train(training_input_fn, steps=steps_per_epoch*EPOCHS)\n",
    "estimator.evaluate(input_fn=validation_input_fn, steps=1)\n",
    "  \n",
    "# call export_savedmodel after training\n",
    "estimator.export_savedmodel(os.path.join(MODEL_DIR, MODEL_EXPORT_NAME), serving_input_fn)\n",
    "tf_logging.set_verbosity(tf_logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0KoTLH5xRLNM"
   },
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    \n",
    "    model = LipCapsule() \n",
    "    num_labels = int(Params.num_labels)\n",
    "\n",
    "    tf.logging.info('  \\n LOADING GRAPH ...  \\n ')\n",
    "    \n",
    "    sv = tf.train.Supervisor(graph=model.graph, logdir=Params.log_path, save_model_secs=0)\n",
    "    \n",
    "    tf.logging.info(' \\n GRAPH LOADED.  \\n ') \n",
    "    \n",
    "    if (mode != tf.estimator.ModeKeys.PREDICT): \n",
    "        tf.logging.info('\\n TRAINING INITATED ... \\n')\n",
    "        train(model, sv, num_labels)\n",
    "        tf.logging.info('\\n TRAINING COMPLETE. \\n')\n",
    "        \n",
    "    else:\n",
    "        tf.logging.info('\\n TEST INITATED ... \\n')\n",
    "        evaluation(model, sv, num_labels)\n",
    "        tf.logging.info('\\n TEST COMPLETE. \\n')\n",
    "        loss = tf.losses.softmax_cross_entropy(labels, logits)\n",
    "    \n",
    "        # Default Estimator summaries appear in Tensorboard.\n",
    "        # metrics_fn needed for TPU\n",
    "        # metrics = {'accuracy': tf.metrics.accuracy(classes, tf.math.argmax(labels, axis=-1))}\n",
    "        metric_fn = lambda classes, labels: {'accuracy': tf.metrics.accuracy(classes, tf.math.argmax(labels, axis=-1))}\n",
    "        tpu_metrics = (metric_fn, [classes, labels])  # metric_fn and list of arguments\n",
    "\n",
    "            else:\n",
    "                loss = train_op = metrics = tpu_metrics = None  \n",
    "                return tf.contrib.tpu.TPUEstimatorSpec(\n",
    "                    mode=mode,\n",
    "                    predictions={\"predictions\": predictions, \"classes\": classes},\n",
    "                    loss=loss, train_op=train_op,\n",
    "                    # metrics_fn must be passed to eval_metrics field \n",
    "                    eval_metrics = tpu_metrics\n",
    "                )\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5tzVi39ShrEL"
   },
   "source": [
    "## Deploy the trained model to ML Engine\n",
    "\n",
    "Push your trained model to production on ML Engine for a serverless, autoscaled, REST API experience.\n",
    "\n",
    "You will need a GCS bucket and a GCP project for this.\n",
    "Models deployed on ML Engine autoscale to zero if not used. There will be no ML Engine charges after you are done testing.\n",
    "Google Cloud Storage incurs charges. Empty the bucket after deployment if you want to avoid these. Once the model is deployed, the bucket is not useful anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Y3ztMY_toCP"
   },
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "iAZAn7yIhqAS",
    "outputId": "6613e32c-a9d9-48f1-c3d4-078721b0466b"
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-d97a8efb7ff3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#export_path = os.path.join(MODEL_DIR, 'export', MODEL_EXPORT_NAME)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mexport_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMODEL_EXPORT_NAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mlast_export\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListDirectory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mexport_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_export\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Saved model directory found: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mlist_directory\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m   \"\"\"\n\u001b[1;32m--> 623\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mlist_directory_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mlist_directory_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    641\u001b[0m   \"\"\"\n\u001b[0;32m    642\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Could not find directory\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     \u001b[1;31m# Convert each element to string, since the return values of the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Could not find directory"
     ]
    }
   ],
   "source": [
    "PROJECT = \"logical-cubist-249306\" #@param {type:\"string\"}\n",
    "NEW_MODEL = True #@param {type:\"boolean\"}\n",
    "MODEL_NAME = \"estimator_tpu_lipcapsule\" #@param {type:\"string\"}\n",
    "MODEL_VERSION = \"v1\" #@param {type:\"string\"}\n",
    "\n",
    "assert PROJECT, 'GCP project'\n",
    "\n",
    "#TPU REFACTORING: TPUEstimator does not create the 'export' subfolder\n",
    "#export_path = os.path.join(MODEL_DIR, 'export', MODEL_EXPORT_NAME)\n",
    "export_path = os.path.join(MODEL_DIR, MODEL_EXPORT_NAME)\n",
    "last_export = sorted(tf.gfile.ListDirectory(export_path))[-1]\n",
    "export_path = os.path.join(export_path, last_export)\n",
    "print('Saved model directory found: ', export_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zy3T3zk0u2J0"
   },
   "source": [
    "### Deploy the model\n",
    "This uses the command-line interface. You can do the same thing through the ML Engine UI at https://console.cloud.google.com/mlengine/models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "nGv3ITiGLPL3",
    "outputId": "27789290-97d4-43aa-d707-71d00d743dd0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gcloud' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "if NEW_MODEL:\n",
    "  !gcloud ml-engine models create {MODEL_NAME} --project={PROJECT} --regions=us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "o3QtUowtOAL-",
    "outputId": "aa7f8fc8-42f2-44cc-b165-1775145f8450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Deployment takes a couple of minutes. You can watch your deployment here: https://console.cloud.google.com/mlengine/models/estimator_tpu_lipcapsule\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gcloud' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Create a version of this model (you can add --async at the end of the line to make this call non blocking)\n",
    "# Additional config flags are available: https://cloud.google.com/ml-engine/reference/rest/v1/projects.models.versions\n",
    "# You can also deploy a model that is stored locally by providing a --staging-bucket=... parameter\n",
    "!echo \"Deployment takes a couple of minutes. You can watch your deployment here: https://console.cloud.google.com/mlengine/models/{MODEL_NAME}\"\n",
    "!gcloud ml-engine versions create {MODEL_VERSION} --model={MODEL_NAME} --origin={export_path} --project={PROJECT} --runtime-version=1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jE-k1Zn6kU2Z"
   },
   "source": [
    "### Test the deployed model\n",
    "Your model is now available as a REST API. Let us try to call it. The cells below use the \"gcloud ml-engine\"\n",
    "command line tool but any tool that can send a JSON payload to a REST endpoint will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pfrtSWlReZ9_"
   },
   "outputs": [],
   "source": [
    "training = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "\n",
    "def evaluation(model, supervisor, labels):\n",
    "    \n",
    "    batch_sz = Params.batch_sz\n",
    "    teX, teY, num_te_batch = load_data(dataset, batch_sz)\n",
    "    \n",
    "    fd_test_acc = save_test()\n",
    "    \n",
    "    with supervisor.managed_session() as sess:\n",
    "        supervisor.saver.restore(sess, tf.train.latest_checkpoint(log_path))\n",
    "        tf.logging.info(' \\n MODEL RESTORED. \\n')\n",
    "\n",
    "        test_acc = 0\n",
    "        \n",
    "        for i in tqdm(range(num_te_batch), total=num_te_batch, ncols=70, leave=False, unit='b'):\n",
    "            start = i * batch_sz\n",
    "            end = start + batch_sz\n",
    "            acc = sess.run(model.accuracy, {model.X: teX[start:end], model.labels: teY[start:end]})\n",
    "            test_acc += acc\n",
    "            \n",
    "        test_acc = test_acc / (batch_sz * num_te_batch)\n",
    "        print(str(test_acc))\n",
    "        fd_test_acc.write(str(test_acc))\n",
    "        \n",
    "        fd_test_acc.close()\n",
    "        \n",
    "        print('  \\n TEST ACCURACY SAVED TO ' + results + '/test_acc.csv  \\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edUbQrjCeW6Z"
   },
   "outputs": [],
   "source": [
    "def save_test():\n",
    "    \n",
    "    test_acc = results + '/test_acc.csv'\n",
    "    \n",
    "    # if os.path.exists(test_acc):\n",
    "    #   os.remove(test_acc)\n",
    "        \n",
    "    fd_test_acc = open(test_acc, 'w')\n",
    "    fd_test_acc.write('test_acc\\n')\n",
    "    \n",
    "    return(fd_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XXSk0bENYB7-"
   },
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hleIN5-pcr0N"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "author: Martin Gorner<br>\n",
    "twitter: @martin_gorner\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Copyright 2018 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "This is not an official Google product but sample code provided for an educational purpose\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Port model to TPUEstimator.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
