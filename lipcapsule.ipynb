{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LipCapsule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        License: Apache-2.0 \n",
    "                \n",
    "        Code adapted for dataset, TPU and Jupyter by Michael E Cruz and Oliver A Ellison (2019)\n",
    "        Email: mecruz@bu.edu, aurelius@bu.edu\n",
    "        Repo: github.com/lipcapsule/TPU\n",
    "        \n",
    "        Adapted from code by Huadong Liao (2017)\n",
    "        Repo: github.com/naturomics/CapsNet-Tensorflow\n",
    "        \n",
    "        Methods for data preprocessing of MIRACL-VC1 dataset based on,\n",
    "        \"Lip reading using CNN and LSTM\" (2016) by Amit Garg, Jonathan Noyola, and Sameep Bagadia.\n",
    "        Stanford Research Paper: http://cs231n.stanford.edu/reports/2016/pdfs/217_Report.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTS -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UGRADE GOOGLE API -- *TPU only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade google-api-python-client\n",
    "!pip3 install --upgrade oauth2client\n",
    "# !pip install --upgrade google-api-python-client\n",
    "# !pip install --upgrade oauth2client\n",
    "\n",
    "_GOOGLE_API_CLIENT_INSTALLED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTS -- *TPU only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import tpu\n",
    "from tensorflow.python.util import compat\n",
    "from tensorflow.contrib.tpu.python.tpu import tpu_function\n",
    "from tensorflow.contrib.cluster_resolver import TPUClusterResolver\n",
    "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import ClusterResolver\n",
    "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import format_master_url\n",
    "from tensorflow.python.distribute.cluster_resolver.cluster_resolver import get_accelerator_devices\n",
    "from googleapiclient import discovery  # pylint: disable=g-import-not-at-top\n",
    "from oauth2client.client import GoogleCredentials  # pylint: disable=g-import-not-at-top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ENVIRONMENT VARIABLES -- *TPU only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_NAME=lips_4\n",
    "STAGING_BUCKET=gs://bucket-4x4\n",
    "REGION=us-central1\n",
    "DATA_DIR=gs://bucket-4x4/data/miracl\n",
    "OUTPUT_PATH=gs://bucket-4x4/logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONNECT WITH TPU SERVER  -- *TPU only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpu_cluster = TPUClusterResolver(\n",
    "    tpu=['TPU_NAME']).get_master()\n",
    "\n",
    "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
    "    FLAGS.tpu,\n",
    "    zone=FLAGS.tpu_zone,\n",
    "    project=FLAGS.gcp_project)\n",
    "\n",
    "config = tpu_config.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    model_dir=FLAGS.model_dir,\n",
    "    save_checkpoints_steps=max(600, FLAGS.iterations_per_loop),\n",
    "    tpu_config=tpu_config.TPUConfig(\n",
    "        iterations_per_loop=FLAGS.iterations_per_loop,\n",
    "        num_shards=FLAGS.num_cores,\n",
    "        per_host_input_for_training=tpu_config.InputPipelineConfig.PER_HOST_V2))\n",
    "\n",
    "# Get the TPU's location\n",
    "with tf.Session(tpu_cluster) as sess:\n",
    "    sess.run(tpu.initialize_system())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SUBMIT TRAINING JOB -- *TPU only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "        --staging-bucket $STAGING_BUCKET \\\n",
    "        --runtime-version 1.13 \\\n",
    "        --scale-tier BASIC_TPU \\\n",
    "        --module-name lipcaps \\\n",
    "        --package-path STAGING_BUCKET/ \\\n",
    "        --region $REGION \\\n",
    "        -- \\\n",
    "        --data_dir=$DATA_DIR \\\n",
    "        --model_dir=$OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FLAGS AND RUNCONFIG -- *TPU only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS(object):\n",
    "    use_tpu=True\n",
    "    tpu_name='TPU_NAME'\n",
    "    model_dir='bucket-4x4'\n",
    "    iterations = 100    # Steps before returning control\n",
    "    num_shards = 8    # TPU has 8 shards\n",
    "\n",
    "if FLAGS.use_tpu:\n",
    "    my_project_name = subprocess.check_output(['gcloud','config','get-value','project'])\n",
    "    my_zone = subprocess.check_output(['gcloud','config','get-value','compute/zone'])\n",
    "    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
    "            tpu=[FLAGS.tpu_name],\n",
    "            zone=my_zone,\n",
    "            project=my_project_name)\n",
    "    master = tpu_cluster_resolver.get_master()\n",
    "else:\n",
    "    master = ''\n",
    "\n",
    "my_tpu_run_config = tf.estimator.tpu.RunConfig(\n",
    "    master=master, evaluation_master=master, model_dir=FLAGS.model_dir, session_config=tf.ConfigProto(\n",
    "        allow_soft_placement=True, log_device_placement=True),\n",
    "    \n",
    "    tpu_config=tf.estimator.tpu.TPUConfig(FLAGS.iterations, FLAGS.num_shards),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CHECK CONNECTION -- *TPU only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'TPU_NAME' not in os.environ:\n",
    "    print('ERROR: NOT CONNECTED TO TPU!')\n",
    "    \n",
    "else:\n",
    "    tpu_address = 'grpc://' + os.environ['TPU_NAME']\n",
    "    print ('TPU address is', tpu_address)\n",
    "\n",
    "    with tf.Session(tpu_address) as session:\n",
    "    devices = session.list_devices()\n",
    "    \n",
    "    print('TPU devices:')\n",
    "    pprint.pprint(devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESTIMATOR -- *GPU only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_estimator = tf.estimator.Estimator(model_fn=LipCapsule())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TPU ESTIMATOR -- *TPU only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tpu_estimator = tf.estimator.tpu.TPUEstimator(\n",
    "    model_fn=my_model_fn,\n",
    "    config=tf.estimator.tpu.RunConfig(),\n",
    "    use_tpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SET GPU -- *GPU only*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IGNORE MEMORY ERRORS -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL PARAMETERS -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params(object):\n",
    "    \n",
    "    batch_sz = 4    # max value\n",
    "    num_threads=2   # system limit\n",
    "    pixels=52       # image h & w\n",
    "    \n",
    "    # Dataset\n",
    "    labels = 10\n",
    "    data_qt=9000\n",
    "    val_qt=data_qt/15\n",
    "    test_qt=data_qt/15\n",
    "    train_qt=data_qt-test_qt-val_qt\n",
    "    \n",
    "    train_sum_freq=100\n",
    "    val_sum_freq=500\n",
    "    save_freq=3\n",
    "    \n",
    "    # Folders\n",
    "    logdir='logdir'\n",
    "    dataset='miracl'\n",
    "    results='results'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MARGIN LOSS PARAMETERS -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_val = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAINING PARAMETERS -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "epsilon = 1e-9    \n",
    "iter_routing = 3\n",
    "mask_with_y = True\n",
    "stddev = 0.01\n",
    "regularization_scale = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LipCapsule Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPLEMENT MODEL -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LipCapsule(object):\n",
    "\n",
    "    def __init__(self, is_training=True, height=Params.pixels, width=Params.pixels, channels=1, num_label=10):\n",
    "        \n",
    "        batch_sz = Params.batch_sz\n",
    "        \n",
    "        \"\"\"\n",
    "            height: input height integer\n",
    "            width: input width integer\n",
    "            channels: input channels integer\n",
    "            num_label: number categories integer\n",
    "        \"\"\"\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.channels = channels\n",
    "        self.num_label = num_label\n",
    "\n",
    "        self.graph = tf.Graph()\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            if is_training:\n",
    "                self.X, self.labels = get_batch_data(dataset, batch_sz, num_threads)\n",
    "                self.Y = tf.one_hot(self.labels, depth=self.num_label, axis=1, dtype=tf.float32)\n",
    "\n",
    "                self.build_arch()\n",
    "                self.loss()\n",
    "                self._summary()\n",
    "\n",
    "                # t_vars = tf.trainable_variables()\n",
    "                self.global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "                self.optimizer = tf.train.AdamOptimizer(0.0005) # original was 0.001\n",
    "                self.train_op = self.optimizer.minimize(self.total_loss, global_step=self.global_step)\n",
    "            else:\n",
    "                self.X = tf.placeholder(tf.float32, shape=(batch_sz, self.height, \n",
    "                                                           self.width, self.channels))\n",
    "                self.labels = tf.placeholder(tf.int32, shape=(batch_sz, ))\n",
    "                self.Y = tf.reshape(self.labels, shape=(batch_sz, self.num_label, 1))\n",
    "                self.build_arch()\n",
    "\n",
    "        tf.logging.info('Setting up the main structure')\n",
    "\n",
    "    def build_arch(self):\n",
    "        \n",
    "        batch_sz = Params.batch_sz\n",
    "        \n",
    "        with tf.variable_scope('Conv1_layer'):\n",
    "            # Conv1, return tensor with shape [batch_size, 20, 20, 256]\n",
    "            conv1 = tf.contrib.layers.conv2d(self.X, num_outputs=256,\n",
    "                                             kernel_size=9, stride=1,\n",
    "                                             padding='VALID')\n",
    "\n",
    "        # Primary Capsules layer returns tensor shaped [batch_size, 1152, 8, 1]\n",
    "        with tf.variable_scope('PrimaryCaps_layer'):\n",
    "            primaryCaps = CapsLayer(num_outputs=32, vec_len=8, with_routing=False, \n",
    "                                    layer_type='CONV')\n",
    "            caps1 = primaryCaps(conv1, kernel_size=9, stride=2)\n",
    "\n",
    "        # DigitCaps layer, return shape [batch_size, 10, 16, 1]\n",
    "        with tf.variable_scope('DigitCaps_layer'):\n",
    "            digitCaps = CapsLayer(num_outputs=self.num_label, vec_len=16, \n",
    "                                  with_routing=True, layer_type='FC')\n",
    "            self.caps2 = digitCaps(caps1)\n",
    "\n",
    "        with tf.variable_scope('Masking'):\n",
    "            # calc ||v_c|| and softmax(||v_c||)\n",
    "            # [batch_size, 10, 16, 1] => [batch_size, 10, 1, 1]\n",
    "            self.v_length = tf.sqrt(reduce_sum(tf.square(self.caps2),\n",
    "                                               axis=2, keepdims=True) + epsilon)\n",
    "            self.softmax_v = softmax(self.v_length, axis=1)\n",
    "            # self.softmax_v.get_shape() == [batch_sz, self.num_label, 1, 1]\n",
    "\n",
    "            # picks out index of max softmax val of 10 caps\n",
    "            # [batch_size, 10, 1, 1] => [batch_size] (index)\n",
    "            self.argmax_idx = tf.to_int32(tf.argmax(self.softmax_v, axis=1))\n",
    "            # self.argmax_idx.get_shape() == [batch_sz, 1, 1]\n",
    "            self.argmax_idx = tf.reshape(self.argmax_idx, shape=(batch_sz, ))\n",
    "\n",
    "            # Not Masking\n",
    "            if not mask_with_y:\n",
    "                # 4-dimensional indexing process\n",
    "                masked_v = []\n",
    "                for batch_size in range(batch_sz):\n",
    "                    v = self.caps2[batch_size][self.argmax_idx[batch_size], :]\n",
    "                    masked_v.append(tf.reshape(v, shape=(1, 1, 16, 1)))\n",
    "\n",
    "                self.masked_v = tf.concat(masked_v, axis=0)\n",
    "                assert self.masked_v.get_shape() == [batch_sz, 1, 16, 1]\n",
    "                \n",
    "            # Masking\n",
    "            else:\n",
    "                self.masked_v = tf.multiply(tf.squeeze(self.caps2), tf.reshape(self.Y, (-1, self.num_label, 1)))\n",
    "                self.v_length = tf.sqrt(reduce_sum(tf.square(self.caps2), axis=2, \n",
    "                                                   keepdims=True) + epsilon)\n",
    "\n",
    "        # MIRACL-VC1 images reconstructed with three (FC) layers\n",
    "        # [batch_size, 1, 16, 1] => [batch_size, 16] => [batch_size, 512]\n",
    "        with tf.variable_scope('Decoder'):\n",
    "            vector_j = tf.reshape(self.masked_v, shape=(batch_sz, -1))\n",
    "            fc1 = tf.contrib.layers.fully_connected(vector_j, num_outputs=512)\n",
    "            fc2 = tf.contrib.layers.fully_connected(fc1, num_outputs=1024)\n",
    "            self.decoded = tf.contrib.layers.fully_connected(\n",
    "                fc2, num_outputs=self.height * self.width * self.channels, activation_fn=tf.sigmoid)\n",
    "\n",
    "    def loss(self):\n",
    "        \n",
    "        batch_sz = Params.batch_sz\n",
    "        \n",
    "        #  Margin loss [batch_size, 10, 1, 1]\n",
    "        # max_l = max(0, m_plus-||v_c||)^2\n",
    "        max_l = tf.square(tf.maximum(0., m_plus - self.v_length))\n",
    "        # max_r = max(0, ||v_c||-m_minus)^2\n",
    "        max_r = tf.square(tf.maximum(0., self.v_length - m_minus))\n",
    "        assert max_l.get_shape() == [batch_sz, self.num_label, 1, 1]\n",
    "\n",
    "        # Reshapes [batch_size, 10, 1, 1] => [batch_size, 10]\n",
    "        max_l = tf.reshape(max_l, shape=(batch_sz, -1))\n",
    "        max_r = tf.reshape(max_r, shape=(batch_sz, -1))\n",
    "\n",
    "        # calc T_c: [batch_size, 10]\n",
    "        T_c = self.Y    # T_c = Y\n",
    "        # element-wise multiply [batch_size, 10]\n",
    "        L_c = T_c * max_l + lambda_val * (1 - T_c) * max_r\n",
    "\n",
    "        self.margin_loss = tf.reduce_mean(tf.reduce_sum(L_c, axis=1))\n",
    "\n",
    "        # Reconstruction loss\n",
    "        orgin = tf.reshape(self.X, shape=(batch_sz, -1))\n",
    "        squared = tf.square(self.decoded - orgin)\n",
    "        self.reconstruction_err = tf.reduce_mean(squared)\n",
    "\n",
    "        # Mean squared error calculated with reduce_mean (reconstruction loss)\n",
    "        self.total_loss = self.margin_loss + regularization_scale * self.reconstruction_err\n",
    "\n",
    "    # Summary\n",
    "    def _summary(self):\n",
    "        \n",
    "        batch_sz = Params.batch_sz\n",
    "        \n",
    "        train_summary = []\n",
    "        train_summary.append(tf.summary.scalar('train/margin_loss', self.margin_loss))\n",
    "        train_summary.append(tf.summary.scalar('train/reconstruction_loss', self.reconstruction_err))\n",
    "        train_summary.append(tf.summary.scalar('train/total_loss', self.total_loss))\n",
    "        recon_img = tf.reshape(self.decoded, shape=(batch_sz, self.height, self.width, self.channels))\n",
    "        train_summary.append(tf.summary.image('reconstruction_img', recon_img))\n",
    "        self.train_summary = tf.summary.merge(train_summary)\n",
    "\n",
    "        correct_prediction = tf.equal(tf.to_int32(self.labels), self.argmax_idx)\n",
    "        self.accuracy = tf.reduce_sum(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CapsLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LAYER CAPSULES -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsLayer(object):\n",
    "    ''' Capsule layer.\n",
    "    Args:\n",
    "        input: A 4-D tensor.\n",
    "        num_outputs: the number of capsule in this layer.\n",
    "        vec_len: integer, the length of the output vector of a capsule.\n",
    "        layer_type: string, one of 'FC' or \"CONV\", the type of this layer,\n",
    "            fully connected or convolution, for the future expansion capability\n",
    "        with_routing: boolean, this capsule is routing with the lower-level layer capsule.\n",
    "\n",
    "    Returns:\n",
    "        A 4-D tensor.\n",
    "    '''\n",
    "    \n",
    "    batch_size = Params.batch_sz\n",
    "    \n",
    "    def __init__(self, num_outputs, vec_len, with_routing=True, layer_type='FC'):\n",
    "        self.num_outputs = num_outputs\n",
    "        self.vec_len = vec_len\n",
    "        self.with_routing = with_routing\n",
    "        self.layer_type = layer_type\n",
    "\n",
    "    def __call__(self, input, kernel_size=None, stride=None):\n",
    "        \n",
    "        # Parameters 'kernel_size' and 'stride' will be used while layer_type = CONV\n",
    "                \n",
    "        batch_sz = Params.batch_sz\n",
    "        \n",
    "        if self.layer_type == 'CONV':\n",
    "            self.kernel_size = kernel_size\n",
    "            self.stride = stride\n",
    "\n",
    "            if not self.with_routing:\n",
    "                # the PrimaryCaps layer, a convolutional layer\n",
    "                # input: [batch_size, 20, 20, 256]\n",
    "                # assert input.get_shape() == [batch_sz, 20, 20, 256]\n",
    "\n",
    "                # NOTE: I can't find out any words from the paper whether the\n",
    "                # PrimaryCap convolution does a ReLU activation or not before\n",
    "                # squashing function, but experiment show that using ReLU get a\n",
    "                # higher test accuracy. So, which one to use will be your choice\n",
    "                capsules = tf.contrib.layers.conv2d(input, self.num_outputs * self.vec_len,\n",
    "                                                    self.kernel_size, self.stride, padding=\"VALID\",\n",
    "                                                    activation_fn=tf.nn.relu)\n",
    "                # capsules = tf.contrib.layers.conv2d(input, self.num_outputs * self.vec_len,\n",
    "                #                                    self.kernel_size, self.stride,padding=\"VALID\",\n",
    "                #                                    activation_fn=None)\n",
    "                capsules = tf.reshape(capsules, (batch_sz, -1, self.vec_len, 1))\n",
    "\n",
    "                # return tensor with shape [batch_size, 1152, 8, 1]\n",
    "                capsules = squash(capsules)\n",
    "                return(capsules)\n",
    "\n",
    "        if self.layer_type == 'FC':\n",
    "            if self.with_routing:\n",
    "                # the DigitCaps layer is fully connected (FC) layer\n",
    "                # Reshapes to [batch_size, 1152, 1, 8, 1]\n",
    "                self.input = tf.reshape(input, shape=(batch_sz, -1, 1, input.shape[-2].value, 1))\n",
    "\n",
    "                with tf.variable_scope('routing'):\n",
    "                    # b_IJ: [batch_size, num_caps_l, num_caps_l_plus_1, 1, 1],\n",
    "                    # about the reason of using 'batch_size', see issue #21\n",
    "                    b_IJ = tf.constant(np.zeros([batch_sz, input.shape[1].value, self.num_outputs, 1, 1], dtype=np.float32))\n",
    "                    capsules = routing(self.input, b_IJ, num_outputs=self.num_outputs, num_dims=self.vec_len)\n",
    "                    capsules = tf.squeeze(capsules, axis=1)\n",
    "\n",
    "            return(capsules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   #### DYNAMIC ROUTING BETWEEN CAPSULES -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "def routing(input, b_IJ, num_outputs=Params.labels, num_dims=16):\n",
    "    \n",
    "    ''' input: Tensor shaped [batch_size, num_caps_l=1152, 1, length(u_i)=8, 1]\n",
    "        num_caps_l: number of  layer l capsules.\n",
    "        num_outputs: number of output capsules.\n",
    "        num_dims: output capsule dimensions.\n",
    "        v_j: vector of capsule j in layer l+1\n",
    "        u_i: vector of capsule i in layer l   \n",
    "        W: [1, num_caps_i, num_caps_j * len_v_j, len_u_j, 1]\n",
    "     '''\n",
    "    batch_sz = Params.batch_sz\n",
    "    \n",
    "    input_shape = get_shape(input)\n",
    "    \n",
    "    W = tf.get_variable('Weight', shape=[1, input_shape[1], num_dims * num_outputs] + input_shape[-2:],\n",
    "                        dtype=tf.float32, initializer=tf.random_normal_initializer(stddev=stddev))\n",
    "    \n",
    "    biases = tf.get_variable('bias', shape=(1, 1, num_outputs, num_dims, 1))\n",
    "\n",
    "    # Element-wise multiply calculates u_hat and reduce_sum\n",
    "    # reshape ops reduces time of tf.matmul operation\n",
    "    \n",
    "    # Matmul [a, b] x [b, c] = element-wise multiply [a*c, b] * [a*c, b]\n",
    "    # reduce_sum at axis=1 and reshape to [a, c]\n",
    "    \n",
    "    input = tf.tile(input, [1, 1, num_dims * num_outputs, 1, 1])\n",
    "    \n",
    "    # input.get_shape() == [batch_size, 1152, 160, 8, 1]\n",
    "    # u_hat.get_shape() == [batch_size, 1152, 10, 16, 1]\n",
    "    \n",
    "    u_hat = reduce_sum(W * input, axis=3, keepdims=True)\n",
    "    u_hat = tf.reshape(u_hat, shape=[-1, input_shape[1], num_outputs, num_dims, 1])\n",
    "    \n",
    "\n",
    "    # u_hat_stopped = u_hat in forward propagation.  \n",
    "    # Gradient not passed back u_hat_stopped to u_hat in backpropagation\n",
    "    \n",
    "    u_hat_stopped = tf.stop_gradient(u_hat, name='stop_gradient')\n",
    "\n",
    "    for r_iter in range(iter_routing):\n",
    "        with tf.variable_scope('iter_' + str(r_iter)):\n",
    "\n",
    "            # => [batch_size, 1152, 10, 1, 1]\n",
    "            c_IJ = softmax(b_IJ, axis=2)\n",
    "\n",
    "            # Final iter uses u_hat to receive gradients from graph\n",
    "            if r_iter == iter_routing - 1:\n",
    "\n",
    "                # weight u_hat with c_IJ, element-wise dimension => [batch_size, 1152, 10, 16, 1]\n",
    "                s_J = tf.multiply(c_IJ, u_hat)\n",
    "                \n",
    "                # sum second dimension = [batch_size, 1, 10, 16, 1]\n",
    "                # s_J.get_shape() == [batch_size, 1, num_outputs, num_dims, 1]\n",
    "                s_J = reduce_sum(s_J, axis=1, keepdims=True) + biases\n",
    "\n",
    "                # squash v_J.get_shape() == [batch_size, 1, 10, 16, 1]\n",
    "                v_J = squash(s_J)\n",
    "                \n",
    "            # No backpropagation here\n",
    "            elif r_iter < iter_routing - 1:  \n",
    "                s_J = tf.multiply(c_IJ, u_hat_stopped)\n",
    "                s_J = reduce_sum(s_J, axis=1, keepdims=True) + biases\n",
    "                v_J = squash(s_J)\n",
    "\n",
    "                # reshape & tile v_j [batch_size ,1, 10, 16, 1] to [batch_size, 1152, 10, 16, 1]\n",
    "                # matmul in the last two dim: [16, 1].T x [16, 1] => [1, 1], reduce mean in the\n",
    "                # batch_size dim, resulting in [1, 1152, 10, 1, 1]\n",
    "                v_J_tiled = tf.tile(v_J, [1, input_shape[1], 1, 1, 1])\n",
    "                u_produce_v = reduce_sum(u_hat_stopped * v_J_tiled, axis=3, keepdims=True)\n",
    "                \n",
    "                # u_produce_v.get_shape() == [batch_size, 1152, 10, 1, 1]\n",
    "                # b_IJ += tf.reduce_sum(u_produce_v, axis=0, keep_dims=True)\n",
    "                b_IJ += u_produce_v\n",
    "\n",
    "    return(v_J)    # Returns: Tensor shaped [batch_size, num_caps_l_plus_1, length(v_j)=16, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQUASH TENSOR -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(vector):\n",
    "    \n",
    "    batch_size = Params.batch_sz\n",
    "    \n",
    "    '''\n",
    "    vector: Tensor shaped [batch_size, 1, num_caps, vec_len, 1] or [batch_size, num_caps, vec_len, 1].\n",
    "    \n",
    "    Returns squashed tensor with 'vec_len' dimensions in same shape as vector.\n",
    "    '''\n",
    "    vec_squared_norm = reduce_sum(tf.square(vector), -2, keepdims=True)\n",
    "    scalar_factor = vec_squared_norm / (1 + vec_squared_norm) / tf.sqrt(vec_squared_norm + epsilon)\n",
    "    vec_squashed = scalar_factor * vector  # element-wise\n",
    "    \n",
    "    return(vec_squashed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOAD DATASET -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size, is_training=True):\n",
    "    \n",
    "    # Method Params\n",
    "    batch_sz = Params.batch_sz\n",
    "    load_qt = Params.train_qt+Params.val_qt\n",
    "    path = os.path.join('data', 'miracl')    # path to dataset\n",
    "    grey = 1\n",
    "    \n",
    "    if is_training:\n",
    "        fd = open(os.path.join(path, 'train-images-idx3-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        trainX = loaded[16:].reshape((load_qt, Params.pixels, Params.pixels, 1)).astype(np.float32)\n",
    "\n",
    "        fd = open(os.path.join(path, 'train-labels-idx1-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        trainY = loaded[8:].reshape((load_qt)).astype(np.int32)\n",
    "\n",
    "        trX = trainX[:Params.train_qt] / 255.\n",
    "        trY = trainY[:Params.train_qt] \n",
    "\n",
    "        valX = trainX[Params.train_qt, ] / 255.\n",
    "        valY = trainY[Params.train_qt:]\n",
    "\n",
    "        num_tr_batch = Params.train_qt // batch_size\n",
    "        num_val_batch = Params.val_qt // batch_size\n",
    "\n",
    "        return trX, trY, num_tr_batch, valX, valY, num_val_batch\n",
    "    else:\n",
    "        fd = open(os.path.join(path, 't10k-images-idx3-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        teX = loaded[16:].reshape((Params.test_qt, Params.pixels, Params.pixels, grey)).astype(np.float)\n",
    "\n",
    "        fd = open(os.path.join(path, 't10k-labels-idx1-ubyte'))\n",
    "        loaded = np.fromfile(file=fd, dtype=np.uint8)\n",
    "        teY = loaded[8:].reshape((Params.test_qt)).astype(np.int32)\n",
    "\n",
    "        num_te_batch = Params.test_qt // batch_size\n",
    "        return teX / 255., teY, num_te_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHUFFLE DATA -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_data(dataset, batch_size, num_threads):\n",
    "    \n",
    "    batch_sz = Params.batch_sz  \n",
    "    \n",
    "    trX, trY, num_tr_batch, valX, valY, num_val_batch = load_data(batch_size, is_training=True)\n",
    "    data_queues = tf.train.slice_input_producer([trX, trY])\n",
    "    \n",
    "    X, Y = tf.train.shuffle_batch(data_queues, num_threads=num_threads, batch_size=batch_size,\n",
    "                                  capacity=batch_size * 64, min_after_dequeue=batch_size * 32,\n",
    "                                  allow_smaller_final_batch=False)\n",
    "\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  MERGE INVERSE TRANSFORM -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(imgs, size, path):\n",
    "    \n",
    "    batch_sz = Params.batch_sz\n",
    "    \n",
    "    '''\n",
    "    Args:\n",
    "        imgs: shaped [batch_size, image_height, image_width]\n",
    "        size: two integers  [image_height, image_width]\n",
    "        path: path to save data\n",
    "    '''\n",
    "    \n",
    "    imgs = (imgs + 1.) / 2    \n",
    "    \n",
    "    return(scipy.misc.imsave(path, mergeImgs(imgs, size)))\n",
    "\n",
    "def mergeImgs(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    imgs = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        imgs[j * h:j * h + h, i * w:i * w + w, :] = image\n",
    "\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOFTMAX -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_sum(input_tensor, axis=None, keepdims=False):\n",
    "    \n",
    "    batch_sz = Params.batch_sz\n",
    "    \n",
    "    try:\n",
    "        return tf.reduce_sum(input_tensor, axis=axis, keepdims=keepdims)\n",
    "    except:\n",
    "        return tf.reduce_sum(input_tensor, axis=axis, keep_dims=keepdims)    # alt for version compatibility\n",
    "    \n",
    "def softmax(logits, axis=None):\n",
    "    try:\n",
    "        return tf.nn.softmax(logits, axis=axis)\n",
    "    except:\n",
    "        return tf.nn.softmax(logits, dim=axis)    # alt for version compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OPTIMIZER -- TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = tf.contrib.tpu.CrossShardOptimizer(\n",
    "            tf.train.AdamOptimizer(0.0005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIST DIMENSIONS -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(inputs, name=None):\n",
    "    \n",
    "    batch_sz = Params.batch_sz\n",
    "    \n",
    "    name = \"shape\" if name is None else name\n",
    "    with tf.name_scope(name):\n",
    "        static_shape = inputs.get_shape().as_list()\n",
    "        dynamic_shape = tf.shape(inputs)\n",
    "        shape = []\n",
    "        for i, dim in enumerate(static_shape):\n",
    "            dim = dim if dim is not None else dynamic_shape[i]\n",
    "            shape.append(dim)\n",
    "        return(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVE ACCURACY PROGRESS (VALIDATION, TRAINING AND LOSS) -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to():\n",
    "    batch_sz = Params.batch_sz        \n",
    "    loss = results + '/loss.csv'\n",
    "    train_acc = results + '/train_acc.csv'\n",
    "    val_acc = results + '/val_acc.csv'\n",
    "    fd_train_acc = open(train_acc, 'w')\n",
    "    fd_train_acc.write('step,train_acc\\n')\n",
    "    fd_loss = open(loss, 'w')\n",
    "    fd_loss.write('step,loss\\n')\n",
    "    fd_val_acc = open(val_acc, 'w')\n",
    "    fd_val_acc.write('step,val_acc\\n')\n",
    "    return(fd_train_acc, fd_loss, fd_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN METHOD -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, supervisor, num_label):\n",
    "    \n",
    "    batch_size = Params.batch_sz  \n",
    "    \n",
    "    trX, trY, num_tr_batch, valX, valY, num_val_batch = load_data(batch_size, is_training=True)\n",
    "    Y = valY[:num_val_batch * batch_size].reshape((-1, 1))\n",
    "\n",
    "    fd_train_acc, fd_loss, fd_val_acc = save_to()\n",
    "    \n",
    "    with supervisor.managed_session() as sess:\n",
    "        for epoch in range(epochs):\n",
    "            print(\"\\n Training.  Epoch %d/%d:\" % (epoch, epochs))\n",
    "            if supervisor.should_stop():\n",
    "                print('\\n Supervisor stoped! \\n ')\n",
    "                break\n",
    "            for step in tqdm(range(num_tr_batch), total=num_tr_batch, ncols=50, leave=False, unit='b'):\n",
    "                start = step * batch_size\n",
    "                end = start + batch_size\n",
    "                global_step = epoch * num_tr_batch + step\n",
    "\n",
    "                if global_step % train_sum_freq == 0:\n",
    "                    _, loss, train_acc, summary_str = sess.run([model.train_op, model.total_loss, \n",
    "                                                                model.accuracy, model.train_summary])\n",
    "                    assert not np.isnan(loss), 'LOSS NAN ERROR'\n",
    "                    \n",
    "                    supervisor.summary_writer.add_summary(summary_str, global_step)\n",
    "\n",
    "                    fd_loss.write(str(global_step) + ',' + str(loss) + \"\\n\")\n",
    "                    fd_loss.flush()\n",
    "                    fd_train_acc.write(str(global_step) + ',' + str(train_acc / batch_size) + \"\\n\")\n",
    "                    fd_train_acc.flush()\n",
    "                else:\n",
    "                    sess.run(model.train_op)\n",
    "\n",
    "                if val_sum_freq != 0 and (global_step) % val_sum_freq == 0:\n",
    "                    val_acc = 0\n",
    "                    for i in range(num_val_batch):\n",
    "                        start = i * batch_size\n",
    "                        end = start + batch_size\n",
    "                        acc = sess.run(model.accuracy, {model.X: valX[start:end], model.labels: valY[start:end]})\n",
    "                        val_acc += acc\n",
    "                    val_acc = val_acc / (batch_size * num_val_batch)\n",
    "                    fd_val_acc.write(str(global_step) + ',' + str(val_acc) + '\\n')\n",
    "                    fd_val_acc.flush()\n",
    "\n",
    "            if (epoch + 1) % save_freq == 0:\n",
    "                supervisor.saver.save(sess, logdir + '/model_epoch_%04d_step_%02d' % (epoch, global_step))\n",
    "\n",
    "        fd_val_acc.close()\n",
    "        fd_train_acc.close()\n",
    "        fd_loss.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SET TO TRAIN -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SET TO TEST -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST ACCURACY -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, supervisor, num_label):\n",
    "    \n",
    "    batch_size = Params.batch_sz\n",
    "    teX, teY, num_te_batch = load_data(batch_size, is_training=False)\n",
    "    \n",
    "    fd_test_acc = save_test()\n",
    "    \n",
    "    with supervisor.managed_session() as sess:\n",
    "        supervisor.saver.restore(sess, tf.train.latest_checkpoint(logdir))\n",
    "        tf.logging.info(' \\n MODEL RESTORED. \\n')\n",
    "\n",
    "        test_acc = 0\n",
    "        \n",
    "        for i in tqdm(range(num_te_batch), total=num_te_batch, ncols=70, leave=False, unit='b'):\n",
    "            start = i * batch_sz\n",
    "            end = start + batch_sz\n",
    "            acc = sess.run(model.accuracy, {model.X: teX[start:end], model.labels: teY[start:end]})\n",
    "            test_acc += acc\n",
    "            \n",
    "        test_acc = test_acc / (batch_size * num_te_batch)\n",
    "        print(str(test_acc))\n",
    "        fd_test_acc.write(str(test_acc))\n",
    "        \n",
    "        fd_test_acc.close()\n",
    "        \n",
    "        print('  \\n TEST ACCURACY SAVED TO ' + results + '/test_acc.csv  \\n ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVE TEST ACCURACY -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_test():\n",
    "    \n",
    "    test_acc = results + '/test_acc.csv'\n",
    "    \n",
    "    # if os.path.exists(test_acc):\n",
    "    #   os.remove(test_acc)\n",
    "        \n",
    "    fd_test_acc = open(test_acc, 'w')\n",
    "    fd_test_acc.write('test_acc\\n')\n",
    "    \n",
    "    return(fd_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAIN METHOD -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    \n",
    "    batch_sz = Params.batch_sz\n",
    "    num_label = 10\n",
    "    model = LipCapsule()\n",
    "    \n",
    "    tf.logging.info('  \\n LOADING GRAPH ...  \\n ')\n",
    "    \n",
    "    sv = tf.train.Supervisor(graph=model.graph, logdir='logdir', save_model_secs=0)\n",
    "    \n",
    "    tf.logging.info(' \\n GRAPH LOADED.  \\n ') \n",
    "    \n",
    "    if is_training: \n",
    "        tf.logging.info(' TRAINING INITATED ...')\n",
    "        train(model, sv, num_label)\n",
    "        tf.logging.info('TRAINING COMPLETE.')\n",
    "        \n",
    "    else:\n",
    "        tf.logging.info(' TEST INITATED ...')\n",
    "        evaluation(model, sv, num_label)\n",
    "        tf.logging.info('TEST COMPLETE.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RUN -- *GPU or TPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting up the main structure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting up the main structure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  \n",
      " LOADING GRAPH ...  \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:  \n",
      " LOADING GRAPH ...  \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: \n",
      " GRAPH LOADED.  \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: \n",
      " GRAPH LOADED.  \n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: TRAINING INITATED ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow: TRAINING INITATED ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting standard services.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting standard services.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting queue runners.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training.  Epoch 0/100:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                     | 0/1300 [00:00<?, ?b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 0.\n",
      " 26%|██▊        | 338/1300 [01:59<05:41,  2.82b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 338.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 338.\n",
      " 58%|██████▍    | 757/1300 [03:59<02:52,  3.15b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 757.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 757.\n",
      " 90%|█████████ | 1175/1300 [06:00<00:38,  3.26b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 1175.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 1175.\n",
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training.  Epoch 1/100:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▍        | 292/1300 [01:26<04:59,  3.37b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 1592.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 1592.\n",
      " 55%|██████     | 710/1300 [03:26<02:51,  3.43b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 2010.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 2010.\n",
      " 90%|████████▉ | 1164/1300 [05:26<00:38,  3.56b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 2464.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 2464.\n",
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training.  Epoch 2/100:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▍        | 282/1300 [01:14<04:28,  3.79b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 2882.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 2882.\n",
      " 54%|█████▉     | 699/1300 [03:14<02:47,  3.60b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 3299.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 3299.\n",
      " 86%|████████▌ | 1118/1300 [05:14<00:51,  3.55b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 3718.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 3718.\n",
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Tensor' object has no attribute 'to_proto'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing global_step.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Tensor' object has no attribute 'to_proto'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training.  Epoch 3/100:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▊         | 220/1300 [01:07<05:31,  3.26b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 4120.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 4120.\n",
      " 49%|█████▍     | 642/1300 [03:07<03:12,  3.42b/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 4542.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Recording summary at step 4542.\n",
      " 84%|████████▎ | 1086/1300 [05:04<01:00,  3.56b/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
